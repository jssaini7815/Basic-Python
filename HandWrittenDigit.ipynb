{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HandWrittenDigit.ipynb",
      "provenance": [],
      "mount_file_id": "1uj1HDVmymlnOdXscmgzGIocqXPrgOWwh",
      "authorship_tag": "ABX9TyM0jdBVxe/ruFQHcSlYBZ2I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jssaini7815/Basic-Python/blob/main/HandWrittenDigit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqGrXf_LT0I1"
      },
      "source": [
        "#Step 2\r\n",
        "#CNN model builder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93zZPP6KTUCa",
        "outputId": "20e7744c-e642-427c-e359-43a44b6018fa"
      },
      "source": [
        "from __future__ import print_function\r\n",
        "import keras\r\n",
        "from keras.datasets import mnist\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Flatten\r\n",
        "from keras.layers import Conv2D, MaxPooling2D\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "batch_size = 128\r\n",
        "num_classes = 10\r\n",
        "epochs = 12\r\n",
        "\r\n",
        "# Input image dimensions\r\n",
        "img_rows, img_cols = 28, 28\r\n",
        "\r\n",
        "# The data, split between train and test sets\r\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n",
        "\r\n",
        "if K.image_data_format() == 'channels_first':\r\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\r\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\r\n",
        "    input_shape = (1, img_rows, img_cols)\r\n",
        "else:\r\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\r\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\r\n",
        "    input_shape = (img_rows, img_cols, 1)\r\n",
        "\r\n",
        "x_train = x_train.astype('float32')\r\n",
        "x_test = x_test.astype('float32')\r\n",
        "\r\n",
        "# Rescale the image values to [0, 1]\r\n",
        "x_train /= 255\r\n",
        "x_test /= 255\r\n",
        "\r\n",
        "# Convert class vectors to binary class matrices\r\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\r\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\r\n",
        "\r\n",
        "# Set the CNN Architecture\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\r\n",
        "                 activation='relu',\r\n",
        "                 input_shape=input_shape))\r\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(128, activation='relu'))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(num_classes, activation='softmax'))\r\n",
        "\r\n",
        "# Comple the model\r\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\r\n",
        "              optimizer=keras.optimizers.Adadelta(),\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "# Train the model\r\n",
        "model.fit(x_train, y_train,\r\n",
        "          batch_size=batch_size,\r\n",
        "          epochs=epochs,\r\n",
        "          verbose=1,\r\n",
        "          validation_data=(x_test, y_test))\r\n",
        "\r\n",
        "# Save the model weights for future reference\r\n",
        "model.save('mnist_cnn_model.h5')\r\n",
        "\r\n",
        "# Evaluate the model using Accuracy and Loss\r\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\r\n",
        "\r\n",
        "print('Test loss:', score[0])\r\n",
        "print('Test accuracy:', score[1])\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 2.2829 - accuracy: 0.1378 - val_loss: 2.2144 - val_accuracy: 0.3391\n",
            "Epoch 2/12\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 2.2075 - accuracy: 0.2609 - val_loss: 2.1121 - val_accuracy: 0.5814\n",
            "Epoch 3/12\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 2.1068 - accuracy: 0.3935 - val_loss: 1.9654 - val_accuracy: 0.6980\n",
            "Epoch 4/12\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.9627 - accuracy: 0.4929 - val_loss: 1.7666 - val_accuracy: 0.7547\n",
            "Epoch 5/12\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.7796 - accuracy: 0.5588 - val_loss: 1.5363 - val_accuracy: 0.7806\n",
            "Epoch 6/12\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.5858 - accuracy: 0.5946 - val_loss: 1.3055 - val_accuracy: 0.7980\n",
            "Epoch 7/12\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.4078 - accuracy: 0.6284 - val_loss: 1.1059 - val_accuracy: 0.8119\n",
            "Epoch 8/12\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.2446 - accuracy: 0.6585 - val_loss: 0.9461 - val_accuracy: 0.8253\n",
            "Epoch 9/12\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.1145 - accuracy: 0.6867 - val_loss: 0.8248 - val_accuracy: 0.8350\n",
            "Epoch 10/12\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.0201 - accuracy: 0.7052 - val_loss: 0.7354 - val_accuracy: 0.8416\n",
            "Epoch 11/12\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.9619 - accuracy: 0.7166 - val_loss: 0.6691 - val_accuracy: 0.8480\n",
            "Epoch 12/12\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.8891 - accuracy: 0.7358 - val_loss: 0.6168 - val_accuracy: 0.8533\n",
            "Test loss: 0.6168049573898315\n",
            "Test accuracy: 0.8532999753952026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIYwbtB-Ts-7"
      },
      "source": [
        "#Step 3\r\n",
        "#Digits recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "OrTX4iQ6TyT2",
        "outputId": "82c7a7dc-08fe-45a6-a492-08a70e52d9d0"
      },
      "source": [
        "from keras.models import load_model\r\n",
        "from collections import deque\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "\r\n",
        "# Load the models built in the previous steps\r\n",
        "mlp_model = load_model('mnist_mlp_model.h5')\r\n",
        "cnn_model = load_model('mnist_cnn_model.h5')\r\n",
        "\r\n",
        "# Define the upper and lower boundaries for a color to be considered \"Blue\"\r\n",
        "blueLower = np.array([100, 60, 60])\r\n",
        "blueUpper = np.array([140, 255, 255])\r\n",
        "\r\n",
        "# Define a 5x5 kernel for erosion and dilation\r\n",
        "kernel = np.ones((5, 5), np.uint8)\r\n",
        "\r\n",
        "# Define Black Board\r\n",
        "blackboard = np.zeros((480,640,3), dtype=np.uint8)\r\n",
        "digit = np.zeros((200, 200, 3), dtype=np.uint8)\r\n",
        "\r\n",
        "# Setup deques to store digits drawn on screen\r\n",
        "points = deque(maxlen=512)\r\n",
        "\r\n",
        "# Define answer variables\r\n",
        "ans1 = ' '\r\n",
        "ans2 = ' '\r\n",
        "\r\n",
        "index = 0\r\n",
        "# Load the video\r\n",
        "camera = cv2.VideoCapture(0)\r\n",
        "\r\n",
        "# Keep looping\r\n",
        "while True:\r\n",
        "    # Grab the current paintWindow\r\n",
        "    (grabbed, frame) = camera.read()\r\n",
        "    frame = cv2.flip(frame, 1)\r\n",
        "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\r\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\r\n",
        "\r\n",
        "    # Determine which pixels fall within the blue boundaries and then blur the binary image\r\n",
        "    blueMask = cv2.inRange(hsv, blueLower, blueUpper)\r\n",
        "    blueMask = cv2.erode(blueMask, kernel, iterations=2)\r\n",
        "    blueMask = cv2.morphologyEx(blueMask, cv2.MORPH_OPEN, kernel)\r\n",
        "    blueMask = cv2.dilate(blueMask, kernel, iterations=1)\r\n",
        "\r\n",
        "    # Find contours (bottle cap in my case) in the image\r\n",
        "    (_, cnts, _) = cv2.findContours(blueMask.copy(), cv2.RETR_EXTERNAL,\r\n",
        "    \tcv2.CHAIN_APPROX_SIMPLE)\r\n",
        "    center = None\r\n",
        "\r\n",
        "    # Check to see if any contours were found\r\n",
        "    if len(cnts) > 0:\r\n",
        "    \t# Sort the contours and find the largest one -- we\r\n",
        "    \t# will assume this contour correspondes to the area of the bottle cap\r\n",
        "        cnt = sorted(cnts, key = cv2.contourArea, reverse = True)[0]\r\n",
        "        # Get the radius of the enclosing circle around the found contour\r\n",
        "        ((x, y), radius) = cv2.minEnclosingCircle(cnt)\r\n",
        "        # Draw the circle around the contour\r\n",
        "        cv2.circle(frame, (int(x), int(y)), int(radius), (0, 255, 255), 2)\r\n",
        "        # Get the moments to calculate the center of the contour (in this case Circle)\r\n",
        "        M = cv2.moments(cnt)\r\n",
        "        center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\r\n",
        "\r\n",
        "        points.appendleft(center)\r\n",
        "\r\n",
        "    elif len(cnts) == 0:\r\n",
        "        if len(points) != 0:\r\n",
        "            blackboard_gray = cv2.cvtColor(blackboard, cv2.COLOR_BGR2GRAY)\r\n",
        "            blur1 = cv2.medianBlur(blackboard_gray, 15)\r\n",
        "            blur1 = cv2.GaussianBlur(blur1, (5, 5), 0)\r\n",
        "            thresh1 = cv2.threshold(blur1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\r\n",
        "            blackboard_cnts = cv2.findContours(thresh1.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[1]\r\n",
        "            if len(blackboard_cnts) >= 1:\r\n",
        "                cnt = sorted(blackboard_cnts, key = cv2.contourArea, reverse = True)[0]\r\n",
        "\r\n",
        "                if cv2.contourArea(cnt) > 1000:\r\n",
        "                    x, y, w, h = cv2.boundingRect(cnt)\r\n",
        "                    digit = blackboard_gray[y-10:y + h + 10, x-10:x + w + 10]\r\n",
        "                    newImage = cv2.resize(digit, (28, 28))\r\n",
        "                    newImage = np.array(newImage)\r\n",
        "                    newImage = newImage.astype('float32')/255\r\n",
        "\r\n",
        "                    ans1 = mlp_model.predict(newImage.reshape(1, 28, 28))[0]\r\n",
        "                    ans1 = np.argmax(ans1)\r\n",
        "                    ans2 = cnn_model.predict(newImage.reshape(1,28,28,1))[0]\r\n",
        "                    ans2 = np.argmax(ans2)\r\n",
        "\r\n",
        "            # Empty the points deque and the blackboard\r\n",
        "            points = deque(maxlen=512)\r\n",
        "            blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\r\n",
        "\r\n",
        "    # Connect the points with a line\r\n",
        "    for i in range(1, len(points)):\r\n",
        "            if points[i - 1] is None or points[i] is None:\r\n",
        "                    continue\r\n",
        "            cv2.line(frame, points[i - 1], points[i], (0, 0, 0), 2)\r\n",
        "            cv2.line(blackboard, points[i - 1], points[i], (255, 255, 255), 8)\r\n",
        "\r\n",
        "    # Put the result on the screen\r\n",
        "    cv2.putText(frame, \"Multilayer Perceptron : \" + str(ans1), (10, 410), cv2.FONT_HERSHEY_SIMPLEX, 0.7,(255, 255, 255), 2)\r\n",
        "    cv2.putText(frame, \"Convolution Neural Network:  \" + str(ans2), (10, 440), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\r\n",
        "\r\n",
        "    # Show the frame\r\n",
        "    cv2.imshow(\"Digits Recognition Real Time\", frame)\r\n",
        "\r\n",
        "    # If the 'q' key is pressed, stop the loop\r\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\r\n",
        "        break\r\n",
        "\r\n",
        "# Cleanup the camera and close any open windows\r\n",
        "camera.release()\r\n",
        "cv2.destroyAllWindows()\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f87893ca8386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mgrabbed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mhsv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QEy_8epUIRs"
      },
      "source": [
        "#Step 1\r\n",
        "#mlp_model_builder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD5Uy_k5UNnO",
        "outputId": "4d82c019-09e9-410e-884e-013e694dca98"
      },
      "source": [
        "from keras.datasets import mnist\r\n",
        "from keras.utils import np_utils\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Flatten\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "\r\n",
        "# Use Keras to import pre-shuffled MNIST database\r\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\r\n",
        "\r\n",
        "print(\"The MNIST database has a training set of %d examples.\" % len(X_train))\r\n",
        "print(\"The MNIST database has a test set of %d examples.\" % len(X_test))\r\n",
        "\r\n",
        "\r\n",
        "# Rescale the Images by Dividing Every Pixel in Every Image by 255\r\n",
        "# Rescale [0,255] --> [0,1]\r\n",
        "\r\n",
        "X_train = X_train.astype('float32')/255\r\n",
        "X_test = X_test.astype('float32')/255\r\n",
        "\r\n",
        "\r\n",
        "# Encode Categorical Integer Labels Using a One-Hot Scheme\r\n",
        "\r\n",
        "y_train = np_utils.to_categorical(y_train, 10)\r\n",
        "y_test = np_utils.to_categorical(y_test, 10)\r\n",
        "\r\n",
        "# Define the Model Architecture\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Flatten(input_shape=X_train.shape[1:]))\r\n",
        "model.add(Dense(512, activation='relu'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(Dense(512, activation='relu'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(Dense(10, activation='softmax'))\r\n",
        "\r\n",
        "# Summarize the model\r\n",
        "# model.summary()\r\n",
        "\r\n",
        "\r\n",
        "# Compile the Model\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "# Calculate the Classification Accuracy on the Test Set (Before Training)\r\n",
        "\r\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\r\n",
        "accuracy = 100*score[1]\r\n",
        "\r\n",
        "print('Before Training - Test accuracy: %.4f%%' % accuracy)\r\n",
        "\r\n",
        "\r\n",
        "# Train the Model\r\n",
        "\r\n",
        "hist = model.fit(X_train, y_train, batch_size=128, epochs=10,\r\n",
        "          validation_split=0.2, verbose=1, shuffle=True)\r\n",
        "\r\n",
        "\r\n",
        "# Load the Model with the Best Classification Accuracy on the Validation Set\r\n",
        "\r\n",
        "model.save('mnist_mlp_model.h5')\r\n",
        "\r\n",
        "# Calculate the Classification Accuracy on the Test Set\r\n",
        "\r\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\r\n",
        "accuracy = 100*score[1]\r\n",
        "\r\n",
        "print('After Training - Test accuracy: %.4f%%' % accuracy)\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The MNIST database has a training set of 60000 examples.\n",
            "The MNIST database has a test set of 10000 examples.\n",
            "Before Training - Test accuracy: 8.6900%\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 3s 5ms/step - loss: 0.2749 - accuracy: 0.9154 - val_loss: 0.1190 - val_accuracy: 0.9648\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1105 - accuracy: 0.9662 - val_loss: 0.0919 - val_accuracy: 0.9741\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0805 - accuracy: 0.9752 - val_loss: 0.0892 - val_accuracy: 0.9749\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0626 - accuracy: 0.9807 - val_loss: 0.1011 - val_accuracy: 0.9743\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0512 - accuracy: 0.9845 - val_loss: 0.0949 - val_accuracy: 0.9773\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0445 - accuracy: 0.9864 - val_loss: 0.0915 - val_accuracy: 0.9781\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0371 - accuracy: 0.9883 - val_loss: 0.1032 - val_accuracy: 0.9783\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0357 - accuracy: 0.9892 - val_loss: 0.0978 - val_accuracy: 0.9786\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0300 - accuracy: 0.9910 - val_loss: 0.1039 - val_accuracy: 0.9791\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.1130 - val_accuracy: 0.9783\n",
            "After Training - Test accuracy: 98.0700%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}